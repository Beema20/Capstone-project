{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\beema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\beema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\beema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "datasets = {\n",
    "    'companies': pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\companies\\companies.csv'),\n",
    "    'company_industries':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\companies\\company_industries.csv'),\n",
    "    'company_specialities':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\companies\\company_specialities.csv'),\n",
    "    'employee_counts':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\companies\\employee_counts.csv'),\n",
    "    'benefits':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\jobs\\benefits.csv'),\n",
    "    'job_industries':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\jobs\\job_industries.csv'),\n",
    "    'job_skills': pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\jobs\\job_skills.csv'),\n",
    "    'salaries':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\jobs\\salaries.csv'),\n",
    "    'industries':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\mappings\\industries.csv'),\n",
    "    'skills':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\mappings\\skills.csv'),\n",
    "    'postings':  pd.read_csv(r'C:\\Users\\beema\\Downloads\\Linkedindataset\\postings.csv')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: companies\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24473 entries, 0 to 24472\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   company_id    24473 non-null  int64  \n",
      " 1   name          24472 non-null  object \n",
      " 2   description   24176 non-null  object \n",
      " 3   company_size  21699 non-null  float64\n",
      " 4   state         24451 non-null  object \n",
      " 5   country       24473 non-null  object \n",
      " 6   city          24472 non-null  object \n",
      " 7   zip_code      24445 non-null  object \n",
      " 8   address       24451 non-null  object \n",
      " 9   url           24473 non-null  object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 1.9+ MB\n",
      "None \n",
      "\n",
      "   company_id                        name  \\\n",
      "0        1009                         IBM   \n",
      "1        1016               GE HealthCare   \n",
      "2        1025  Hewlett Packard Enterprise   \n",
      "3        1028                      Oracle   \n",
      "4        1033                   Accenture   \n",
      "\n",
      "                                         description  company_size  state  \\\n",
      "0  At IBM, we do more than work. We create. We cr...           7.0     NY   \n",
      "1  Every day millions of people feel the impact o...           7.0      0   \n",
      "2  Official LinkedIn of Hewlett Packard Enterpris...           7.0  Texas   \n",
      "3  Weâ€™re a cloud technology company that provides...           7.0  Texas   \n",
      "4  Accenture is a leading global professional ser...           7.0      0   \n",
      "\n",
      "  country              city zip_code                                address  \\\n",
      "0      US  Armonk, New York    10504  International Business Machines Corp.   \n",
      "1      US           Chicago        0                                      -   \n",
      "2      US           Houston    77389            1701 E Mossy Oaks Rd Spring   \n",
      "3      US            Austin    78741                        2300 Oracle Way   \n",
      "4      IE          Dublin 2        0                    Grand Canal Harbour   \n",
      "\n",
      "                                                 url  \n",
      "0               https://www.linkedin.com/company/ibm  \n",
      "1      https://www.linkedin.com/company/gehealthcare  \n",
      "2  https://www.linkedin.com/company/hewlett-packa...  \n",
      "3            https://www.linkedin.com/company/oracle  \n",
      "4         https://www.linkedin.com/company/accenture   \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: company_industries\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24375 entries, 0 to 24374\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   company_id  24375 non-null  int64 \n",
      " 1   industry    24375 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 381.0+ KB\n",
      "None \n",
      "\n",
      "   company_id                        industry\n",
      "0      391906  Book and Periodical Publishing\n",
      "1    22292832                    Construction\n",
      "2       20300                         Banking\n",
      "3     3570660  Book and Periodical Publishing\n",
      "4      878353         Staffing and Recruiting \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: company_specialities\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169387 entries, 0 to 169386\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   company_id  169387 non-null  int64 \n",
      " 1   speciality  169387 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None \n",
      "\n",
      "   company_id              speciality\n",
      "0    22292832      window replacement\n",
      "1    22292832  patio door replacement\n",
      "2       20300      Commercial Banking\n",
      "3       20300          Retail Banking\n",
      "4       20300                Mortgage \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: employee_counts\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35787 entries, 0 to 35786\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   company_id      35787 non-null  int64\n",
      " 1   employee_count  35787 non-null  int64\n",
      " 2   follower_count  35787 non-null  int64\n",
      " 3   time_recorded   35787 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 1.1 MB\n",
      "None \n",
      "\n",
      "   company_id  employee_count  follower_count  time_recorded\n",
      "0      391906             186           32508     1712346173\n",
      "1    22292832             311            4471     1712346173\n",
      "2       20300            1053            6554     1712346173\n",
      "3     3570660             383           35241     1712346173\n",
      "4      878353              52           26397     1712346173 \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: benefits\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67943 entries, 0 to 67942\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   job_id    67943 non-null  int64 \n",
      " 1   inferred  67943 non-null  int64 \n",
      " 2   type      67943 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None \n",
      "\n",
      "       job_id  inferred                     type\n",
      "0  3887473071         0        Medical insurance\n",
      "1  3887473071         0         Vision insurance\n",
      "2  3887473071         0         Dental insurance\n",
      "3  3887473071         0                   401(k)\n",
      "4  3887473071         0  Student loan assistance \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: job_industries\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164808 entries, 0 to 164807\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype\n",
      "---  ------       --------------   -----\n",
      " 0   job_id       164808 non-null  int64\n",
      " 1   industry_id  164808 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 2.5 MB\n",
      "None \n",
      "\n",
      "       job_id  industry_id\n",
      "0  3884428798           82\n",
      "1  3887473071           48\n",
      "2  3887465684           41\n",
      "3  3887467939           82\n",
      "4  3887467939           80 \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: job_skills\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213768 entries, 0 to 213767\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   job_id     213768 non-null  int64 \n",
      " 1   skill_abr  213768 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.3+ MB\n",
      "None \n",
      "\n",
      "       job_id skill_abr\n",
      "0  3884428798      MRKT\n",
      "1  3884428798        PR\n",
      "2  3884428798       WRT\n",
      "3  3887473071      SALE\n",
      "4  3887465684       FIN \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: salaries\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40785 entries, 0 to 40784\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   salary_id          40785 non-null  int64  \n",
      " 1   job_id             40785 non-null  int64  \n",
      " 2   max_salary         33947 non-null  float64\n",
      " 3   med_salary         6838 non-null   float64\n",
      " 4   min_salary         33947 non-null  float64\n",
      " 5   pay_period         40785 non-null  object \n",
      " 6   currency           40785 non-null  object \n",
      " 7   compensation_type  40785 non-null  object \n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 2.5+ MB\n",
      "None \n",
      "\n",
      "   salary_id      job_id  max_salary  med_salary  min_salary pay_period  \\\n",
      "0          1  3884428798         NaN        20.0         NaN     HOURLY   \n",
      "1          2  3887470552        25.0         NaN        23.0     HOURLY   \n",
      "2          3  3884431523    120000.0         NaN    100000.0     YEARLY   \n",
      "3          4  3884911725    200000.0         NaN     10000.0     YEARLY   \n",
      "4          5  3887473220        35.0         NaN        33.0     HOURLY   \n",
      "\n",
      "  currency compensation_type  \n",
      "0      USD       BASE_SALARY  \n",
      "1      USD       BASE_SALARY  \n",
      "2      USD       BASE_SALARY  \n",
      "3      USD       BASE_SALARY  \n",
      "4      USD       BASE_SALARY   \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: industries\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   industry_id    422 non-null    int64 \n",
      " 1   industry_name  388 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.7+ KB\n",
      "None \n",
      "\n",
      "   industry_id                         industry_name\n",
      "0            1       Defense and Space Manufacturing\n",
      "1            3       Computer Hardware Manufacturing\n",
      "2            4                  Software Development\n",
      "3            5          Computer Networking Products\n",
      "4            6  Technology, Information and Internet \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: skills\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   skill_abr   35 non-null     object\n",
      " 1   skill_name  35 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 692.0+ bytes\n",
      "None \n",
      "\n",
      "  skill_abr          skill_name\n",
      "0       ART        Art/Creative\n",
      "1      DSGN              Design\n",
      "2      ADVR         Advertising\n",
      "3      PRDM  Product Management\n",
      "4      DIST        Distribution \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: postings\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 28 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                122130 non-null  object \n",
      " 2   title                       123849 non-null  object \n",
      " 3   description                 123842 non-null  object \n",
      " 4   max_salary                  29793 non-null   float64\n",
      " 5   pay_period                  36073 non-null   object \n",
      " 6   location                    123849 non-null  object \n",
      " 7   company_id                  122132 non-null  float64\n",
      " 8   views                       122160 non-null  float64\n",
      " 9   med_salary                  6280 non-null    float64\n",
      " 10  min_salary                  29793 non-null   float64\n",
      " 11  formatted_work_type         123849 non-null  object \n",
      " 12  applies                     23320 non-null   float64\n",
      " 13  original_listed_time        123849 non-null  float64\n",
      " 14  remote_allowed              15246 non-null   float64\n",
      " 15  job_posting_url             123849 non-null  object \n",
      " 16  application_url             87184 non-null   object \n",
      " 17  application_type            123849 non-null  object \n",
      " 18  expiry                      123849 non-null  float64\n",
      " 19  closed_time                 1073 non-null    float64\n",
      " 20  formatted_experience_level  94440 non-null   object \n",
      " 21  skills_desc                 2439 non-null    object \n",
      " 22  listed_time                 123849 non-null  float64\n",
      " 23  posting_domain              83881 non-null   object \n",
      " 24  sponsored                   123849 non-null  int64  \n",
      " 25  work_type                   123849 non-null  object \n",
      " 26  currency                    36073 non-null   object \n",
      " 27  compensation_type           36073 non-null   object \n",
      "dtypes: float64(11), int64(2), object(15)\n",
      "memory usage: 26.5+ MB\n",
      "None \n",
      "\n",
      "     job_id            company_name  \\\n",
      "0    921716   Corcoran Sawyer Smith   \n",
      "1   1829192                     NaN   \n",
      "2  10998357  The National Exemplar    \n",
      "3  23221523  Abrams Fensterman, LLP   \n",
      "4  35982263                     NaN   \n",
      "\n",
      "                                               title  \\\n",
      "0                              Marketing Coordinator   \n",
      "1                  Mental Health Therapist/Counselor   \n",
      "2                        Assitant Restaurant Manager   \n",
      "3  Senior Elder Law / Trusts and Estates Associat...   \n",
      "4                                 Service Technician   \n",
      "\n",
      "                                         description  max_salary pay_period  \\\n",
      "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
      "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
      "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
      "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
      "4  Looking for HVAC service tech with experience ...     80000.0     YEARLY   \n",
      "\n",
      "            location  company_id  views  med_salary  ...        expiry  \\\n",
      "0      Princeton, NJ   2774458.0   20.0         NaN  ...  1.715990e+12   \n",
      "1   Fort Collins, CO         NaN    1.0         NaN  ...  1.715450e+12   \n",
      "2     Cincinnati, OH  64896719.0    8.0         NaN  ...  1.715870e+12   \n",
      "3  New Hyde Park, NY    766262.0   16.0         NaN  ...  1.715488e+12   \n",
      "4     Burlington, IA         NaN    3.0         NaN  ...  1.716044e+12   \n",
      "\n",
      "  closed_time  formatted_experience_level  \\\n",
      "0         NaN                         NaN   \n",
      "1         NaN                         NaN   \n",
      "2         NaN                         NaN   \n",
      "3         NaN                         NaN   \n",
      "4         NaN                         NaN   \n",
      "\n",
      "                                         skills_desc   listed_time  \\\n",
      "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
      "1                                                NaN  1.712858e+12   \n",
      "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
      "3  This position requires a baseline understandin...  1.712896e+12   \n",
      "4                                                NaN  1.713452e+12   \n",
      "\n",
      "  posting_domain sponsored  work_type  currency  compensation_type  \n",
      "0            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "1            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "2            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "3            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "4            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "\n",
      "[5 rows x 28 columns] \n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display info and first few rows of all DataFrames\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(df.info(), '\\n')\n",
    "    print(df.head(), '\\n')\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in companies:\n",
      "company_id         0\n",
      "name               1\n",
      "description      297\n",
      "company_size    2774\n",
      "state             22\n",
      "country            0\n",
      "city               1\n",
      "zip_code          28\n",
      "address           22\n",
      "url                0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in company_industries:\n",
      "company_id    0\n",
      "industry      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in company_specialities:\n",
      "company_id    0\n",
      "speciality    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in employee_counts:\n",
      "company_id        0\n",
      "employee_count    0\n",
      "follower_count    0\n",
      "time_recorded     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in benefits:\n",
      "job_id      0\n",
      "inferred    0\n",
      "type        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in job_industries:\n",
      "job_id         0\n",
      "industry_id    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in job_skills:\n",
      "job_id       0\n",
      "skill_abr    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in salaries:\n",
      "salary_id                0\n",
      "job_id                   0\n",
      "max_salary            6838\n",
      "med_salary           33947\n",
      "min_salary            6838\n",
      "pay_period               0\n",
      "currency                 0\n",
      "compensation_type        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in industries:\n",
      "industry_id       0\n",
      "industry_name    34\n",
      "dtype: int64\n",
      "\n",
      "Missing values in skills:\n",
      "skill_abr     0\n",
      "skill_name    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in postings:\n",
      "job_id                             0\n",
      "company_name                    1719\n",
      "title                              0\n",
      "description                        7\n",
      "max_salary                     94056\n",
      "pay_period                     87776\n",
      "location                           0\n",
      "company_id                      1717\n",
      "views                           1689\n",
      "med_salary                    117569\n",
      "min_salary                     94056\n",
      "formatted_work_type                0\n",
      "applies                       100529\n",
      "original_listed_time               0\n",
      "remote_allowed                108603\n",
      "job_posting_url                    0\n",
      "application_url                36665\n",
      "application_type                   0\n",
      "expiry                             0\n",
      "closed_time                   122776\n",
      "formatted_experience_level     29409\n",
      "skills_desc                   121410\n",
      "listed_time                        0\n",
      "posting_domain                 39968\n",
      "sponsored                          0\n",
      "work_type                          0\n",
      "currency                       87776\n",
      "compensation_type              87776\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find missing values\n",
    "def find_missing_values(df):\n",
    "    return df.isnull().sum()\n",
    "\n",
    "# Check for missing values in each dataset\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Missing values in {name}:\")\n",
    "    print(find_missing_values(df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "companies have missing values in 7 columns name, description, company_size, state, city, zip_code, address\n",
    "salaries have missing values in 3: max_salary, med_salary, min_salary\n",
    "industries have missing values in industry_name    \n",
    "postings have missing values in 17 columns                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in companies:\n",
      "company_id      0\n",
      "name            0\n",
      "description     0\n",
      "company_size    0\n",
      "state           0\n",
      "country         0\n",
      "city            0\n",
      "zip_code        0\n",
      "address         0\n",
      "url             0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in company_industries:\n",
      "company_id    0\n",
      "industry      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in company_specialities:\n",
      "company_id    0\n",
      "speciality    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in employee_counts:\n",
      "company_id        0\n",
      "employee_count    0\n",
      "follower_count    0\n",
      "time_recorded     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in benefits:\n",
      "job_id      0\n",
      "inferred    0\n",
      "type        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in job_industries:\n",
      "job_id         0\n",
      "industry_id    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in job_skills:\n",
      "job_id       0\n",
      "skill_abr    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in salaries:\n",
      "salary_id            0\n",
      "job_id               0\n",
      "max_salary           0\n",
      "min_salary           0\n",
      "pay_period           0\n",
      "currency             0\n",
      "compensation_type    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in industries:\n",
      "industry_id      0\n",
      "industry_name    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in skills:\n",
      "skill_abr     0\n",
      "skill_name    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in postings:\n",
      "job_id                        0\n",
      "company_name                  0\n",
      "title                         0\n",
      "description                   0\n",
      "max_salary                    0\n",
      "pay_period                    0\n",
      "location                      0\n",
      "company_id                    0\n",
      "views                         0\n",
      "min_salary                    0\n",
      "formatted_work_type           0\n",
      "applies                       0\n",
      "original_listed_time          0\n",
      "remote_allowed                0\n",
      "job_posting_url               0\n",
      "application_url               0\n",
      "application_type              0\n",
      "expiry                        0\n",
      "formatted_experience_level    0\n",
      "skills_desc                   0\n",
      "listed_time                   0\n",
      "posting_domain                0\n",
      "sponsored                     0\n",
      "work_type                     0\n",
      "currency                      0\n",
      "compensation_type             0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values in companies dataset\n",
    "companies = datasets['companies']\n",
    "companies['name'].fillna('Unknown', inplace=True)\n",
    "companies['description'].fillna('', inplace=True)\n",
    "companies['company_size'].fillna(companies['company_size'].median(), inplace=True)\n",
    "companies.dropna(subset=['state'], inplace=True)\n",
    "companies.dropna(subset=['city'], inplace=True)\n",
    "companies.dropna(subset=['zip_code'], inplace=True)\n",
    "companies['address'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Handle missing values in salaries dataset\n",
    "salaries = datasets['salaries']\n",
    "salaries['max_salary'].fillna(salaries['max_salary'].mean(), inplace=True)\n",
    "salaries['min_salary'].fillna(salaries['min_salary'].mean(), inplace=True)\n",
    "salaries.drop(columns=['med_salary'], inplace=True)\n",
    "\n",
    "# Handle missing values in industries dataset\n",
    "industries = datasets['industries']\n",
    "industries.dropna(subset=['industry_name'], inplace=True)\n",
    "\n",
    "# Handle missing values in postings dataset\n",
    "postings = datasets['postings']\n",
    "postings['company_name'].fillna('Unknown', inplace=True)\n",
    "postings['description'].fillna('', inplace=True)\n",
    "postings['max_salary'].fillna(postings['max_salary'].mean(), inplace=True)\n",
    "postings['min_salary'].fillna(postings['min_salary'].mean(), inplace=True)\n",
    "postings['pay_period'].fillna(postings['pay_period'].mode()[0], inplace=True)\n",
    "postings['currency'].fillna(postings['currency'].mode()[0], inplace=True)\n",
    "postings['compensation_type'].fillna(postings['compensation_type'].mode()[0], inplace=True)\n",
    "postings.dropna(subset=['company_id'], inplace=True)\n",
    "postings['views'].fillna(0, inplace=True)\n",
    "postings.drop(columns=['med_salary'], inplace=True)\n",
    "postings['applies'].fillna(0, inplace=True)\n",
    "postings['remote_allowed'].fillna(0, inplace=True)\n",
    "postings['application_url'].fillna('Unknown', inplace=True)\n",
    "postings.drop(columns=['closed_time'], inplace=True)\n",
    "postings['formatted_experience_level'].fillna(postings['formatted_experience_level'].mode()[0], inplace=True)\n",
    "postings['skills_desc'].fillna('', inplace=True)\n",
    "postings['posting_domain'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Confirm changes\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Missing values in {name}:\")\n",
    "    print(df.isnull().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords and non-alphanumeric tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the preprocessing function to the relevant text columns in datasets\n",
    "datasets['companies']['description'] = datasets['companies']['description'].apply(preprocess_text)\n",
    "datasets['postings']['description'] = datasets['postings']['description'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge company_industries with companies\n",
    "company_industries = datasets['company_industries']\n",
    "companies = datasets['companies'].merge(company_industries, on='company_id', how='left')\n",
    "\n",
    "# Merge company_specialities with companies\n",
    "company_specialities = datasets['company_specialities']\n",
    "companies = companies.merge(company_specialities, on='company_id', how='left')\n",
    "\n",
    "# Merge employee_counts with companies\n",
    "employee_counts = datasets['employee_counts']\n",
    "companies = companies.merge(employee_counts, on='company_id', how='left')\n",
    "\n",
    "# Update the datasets dictionary\n",
    "datasets['companies'] = companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge job_industries with postings\n",
    "job_industries = datasets['job_industries']\n",
    "postings = datasets['postings'].merge(job_industries, on='job_id', how='left')\n",
    "\n",
    "# Merge job_skills with postings\n",
    "job_skills = datasets['job_skills']\n",
    "postings = postings.merge(job_skills, on='job_id', how='left')\n",
    "\n",
    "# Merge salaries with postings\n",
    "salaries = datasets['salaries']\n",
    "postings = postings.merge(salaries, on='job_id', how='left')\n",
    "\n",
    "# Merge benefits with postings\n",
    "benefits = datasets['benefits']\n",
    "postings = postings.merge(benefits, on='job_id', how='left')\n",
    "\n",
    "# Update the datasets dictionary\n",
    "datasets['postings'] = postings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Encode Categorical Variables\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical columns in companies dataset\n",
    "for column in ['name', 'description', 'state', 'country', 'city', 'address']:\n",
    "    if column in companies.columns:\n",
    "        le = LabelEncoder()\n",
    "        companies[column] = le.fit_transform(companies[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode categorical columns in company_industries dataset\n",
    "for column in ['industry']:\n",
    "    if column in company_industries.columns:\n",
    "        le = LabelEncoder()\n",
    "        company_industries[column] = le.fit_transform(company_industries[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode categorical columns in skills dataset\n",
    "for column in ['skill_name']:\n",
    "    if column in skills.columns:\n",
    "        le = LabelEncoder()\n",
    "        skills[column] = le.fit_transform(skills[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode categorical columns in industries dataset\n",
    "for column in ['industry_name']:\n",
    "    if column in industries.columns:\n",
    "        le = LabelEncoder()\n",
    "        industries[column] = le.fit_transform(industries[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Encode categorical columns in postings dataset\n",
    "for column in ['company_name', 'title', 'description', 'pay_period', 'location', 'formatted_experience_level', 'skills_desc', 'posting_domain', 'compensation_type']:\n",
    "    if column in postings.columns:\n",
    "        le = LabelEncoder()\n",
    "        postings[column] = le.fit_transform(postings[column])\n",
    "        label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Extract job location features from address\n",
    "if 'state' in companies.columns and 'city' in companies.columns:\n",
    "    companies['location'] = companies['state'].astype(str) + '_' + companies['city'].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    companies['location'] = le.fit_transform(companies['location'])\n",
    "    label_encoders['location'] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Numerical Features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale numerical columns in companies dataset\n",
    "if 'company_size' in companies.columns:\n",
    "    companies[['company_size']] = scaler.fit_transform(companies[['company_size']])\n",
    "\n",
    "# Scale numerical columns in postings dataset\n",
    "for column in ['max_salary', 'min_salary', 'views', 'applies']:\n",
    "    if column in postings.columns:\n",
    "        postings[[column]] = scaler.fit_transform(postings[[column]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
